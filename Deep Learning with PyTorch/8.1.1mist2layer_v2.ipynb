{"cells":[{"cell_type":"markdown","id":"bbdc44ea-c63e-4548-928b-f5d08a6f0259","metadata":{},"outputs":[],"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"f6053dfb-fbc5-44e0-b2cd-c5c648fda0f2","metadata":{},"outputs":[],"source":["<h1>Deep Neural Networks</h1>\n"]},{"cell_type":"markdown","id":"0fe97e97-3113-4f95-9969-5f79063d211b","metadata":{},"outputs":[],"source":["\n","<h3>Objective for this Notebook<h3>    \n","<h5> 1. Define Several Neural Network, Criterion function, Optimizer.</h5>\n","<h5> 2. Test Sigmoid ,Tanh and Relu. </h5>\n","<h5> 3. Analyse Results. </h5>     \n","\n"]},{"cell_type":"markdown","id":"e9a14aec-dd7b-4cc4-80cf-df4a40f9f1cd","metadata":{},"outputs":[],"source":["<h2>Table of Contents</h2>\n","<p>In this lab, you will test Sigmoid, Tanh and Relu activation functions on the MNIST dataset with two hidden Layers.</p>\n","\n","<ul>\n","    <li><a href=\"#Model\">Neural Network Module and Training Function</a></li>\n","    <li><a href=\"#Makeup_Data\">Make Some Data</a></li>\n","    <li><a href=\"#Train\">Define Several Neural Network, Criterion function, Optimizer</a></li>\n","    <li><a href=\"#Test\">Test Sigmoid ,Tanh and Relu </a></li>\n","    <li><a href=\"#Result\">Analyse Results</a></li>\n","</ul>\n","<p>Estimated Time Needed: <strong>25 min</strong></p>\n","\n","<hr>\n"]},{"cell_type":"markdown","id":"21723d05-596e-4769-9c96-082715425be6","metadata":{},"outputs":[],"source":["We'll need the following libraries\n"]},{"cell_type":"code","id":"f3c529f8-9613-46c8-8d38-e3b426f75259","metadata":{},"outputs":[],"source":["# Import the libraries we need for this lab\n\n# Using the following line code to install the torchvision library\n# !mamba install -y torchvision\n\n!pip install torchvision==0.9.1 torch==1.8.1 \nimport torch \nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dsets\nimport torch.nn.functional as F\nimport matplotlib.pylab as plt\nimport numpy as np\ntorch.manual_seed(2)"]},{"cell_type":"markdown","id":"373f29ee-5d83-4050-94ab-d0c30c3d476b","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"1eaad711-1772-4cde-819f-da819724d60e","metadata":{},"outputs":[],"source":["<a name=\"Model\"><h2 id=\"Model\">Neural Network Module and Training Function</h2></a>\n"]},{"cell_type":"markdown","id":"a7f9fe0d-c0ee-4e83-82b6-ca55eb85b7fe","metadata":{},"outputs":[],"source":["Define the neural network module or class, with two hidden Layers \n"]},{"cell_type":"markdown","id":"250119a1-e079-4f74-8cc3-fecf5afac534","metadata":{},"outputs":[],"source":["<img src=\"https://ibm.box.com/shared/static/5wtclahun0f70qlwkn2kxzh3amnbq4zg.png\" width=\"200\" alt=\"Neural Network Model\">\n"]},{"cell_type":"code","id":"2925839d-36f6-4abc-b893-07a1b681cd45","metadata":{},"outputs":[],"source":["# Create the model class using sigmoid as the activation function\n\nclass Net(nn.Module):\n    \n    # Constructor\n    def __init__(self, D_in, H1, H2, D_out):\n        super(Net, self).__init__()\n        self.linear1 = nn.Linear(D_in, H1)\n        self.linear2 = nn.Linear(H1, H2)\n        self.linear3 = nn.Linear(H2, D_out)\n    \n    # Prediction\n    def forward(self,x):\n        x = torch.sigmoid(self.linear1(x)) \n        x = torch.sigmoid(self.linear2(x))\n        x = self.linear3(x)\n        return x"]},{"cell_type":"markdown","id":"84c7455a-e06c-4c09-978e-c79f76b511bd","metadata":{},"outputs":[],"source":["Define the class with the Tanh activation function \n"]},{"cell_type":"code","id":"67e45c6c-867c-46b7-b7a8-46d96fe611f0","metadata":{},"outputs":[],"source":["# Create the model class using Tanh as a activation function\n\nclass NetTanh(nn.Module):\n    \n    # Constructor\n    def __init__(self, D_in, H1, H2, D_out):\n        super(NetTanh, self).__init__()\n        self.linear1 = nn.Linear(D_in, H1)\n        self.linear2 = nn.Linear(H1, H2)\n        self.linear3 = nn.Linear(H2, D_out)\n    \n    # Prediction\n    def forward(self, x):\n        x = torch.tanh(self.linear1(x))\n        x = torch.tanh(self.linear2(x))\n        x = self.linear3(x)\n        return x"]},{"cell_type":"markdown","id":"db0ca4dd-9bac-42db-85f8-3760d0f80b47","metadata":{},"outputs":[],"source":["Define the class for the Relu activation function \n"]},{"cell_type":"code","id":"40e93e54-fc76-40e9-9ac2-9f3fee24ee57","metadata":{},"outputs":[],"source":["# Create the model class using Relu as a activation function\n\nclass NetRelu(nn.Module):\n    \n    # Constructor\n    def __init__(self, D_in, H1, H2, D_out):\n        super(NetRelu, self).__init__()\n        self.linear1 = nn.Linear(D_in, H1)\n        self.linear2 = nn.Linear(H1, H2)\n        self.linear3 = nn.Linear(H2, D_out)\n    \n    # Prediction\n    def forward(self, x):\n        x = torch.relu(self.linear1(x))  \n        x = torch.relu(self.linear2(x))\n        x = self.linear3(x)\n        return x"]},{"cell_type":"markdown","id":"1208479d-07fa-4c0f-87e3-7b1e6c64f97d","metadata":{},"outputs":[],"source":["Define a function to  train the model, in this case the function returns a Python dictionary to store the training loss and accuracy on the validation data \n"]},{"cell_type":"code","id":"cac9e521-0b65-4ebd-9793-3f6ee2d53332","metadata":{},"outputs":[],"source":["# Train the model\n\ndef train(model, criterion, train_loader, validation_loader, optimizer, epochs=100):\n    i = 0\n    useful_stuff = {'training_loss': [], 'validation_accuracy': []}  \n    \n    for epoch in range(epochs):\n        for i, (x, y) in enumerate(train_loader):\n            optimizer.zero_grad()\n            z = model(x.view(-1, 28 * 28))\n            loss = criterion(z, y)\n            loss.backward()\n            optimizer.step()\n            useful_stuff['training_loss'].append(loss.data.item())\n        \n        correct = 0\n        for x, y in validation_loader:\n            z = model(x.view(-1, 28 * 28))\n            _, label = torch.max(z, 1)\n            correct += (label == y).sum().item()\n    \n        accuracy = 100 * (correct / len(validation_dataset))\n        useful_stuff['validation_accuracy'].append(accuracy)\n    \n    return useful_stuff"]},{"cell_type":"markdown","id":"7572c8e0-c3f7-4751-b136-3121ef8da7f8","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"feab0773-248a-47b5-b524-1f21df48268a","metadata":{},"outputs":[],"source":["<a name=\"Makeup_Data\"><h2 id=\"Makeup_Data\">Make Some Data</h2></a>\n"]},{"cell_type":"markdown","id":"f6051416-a0f0-43c3-9364-393afc1f869e","metadata":{},"outputs":[],"source":["Load the training dataset by setting the parameters <code>train</code> to <code>True</code> and convert it to a tensor  by placing a transform object int the argument <code>transform</code>\n"]},{"cell_type":"code","id":"a4bc6a19-7469-4149-bb8c-e88e5e4f8c2a","metadata":{},"outputs":[],"source":["# Create the training dataset\n\ntrain_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())"]},{"cell_type":"markdown","id":"5309eb7b-b6f6-4e99-b234-7ffd079a10be","metadata":{},"outputs":[],"source":["Load the testing dataset by setting the parameters <code>train</code> to <code>False</code> and convert it to a tensor  by placing a transform object int the argument <code>transform</code>\n"]},{"cell_type":"code","id":"8fd619b7-3d26-4766-85cd-5a30914066dc","metadata":{},"outputs":[],"source":["# Create the validating dataset\n\nvalidation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"]},{"cell_type":"markdown","id":"12ac4f34-fc5f-4b77-829e-4cc27fa921ac","metadata":{},"outputs":[],"source":["Create the criterion function  \n"]},{"cell_type":"code","id":"62884b47-88ab-487d-a374-da606f7f1b0a","metadata":{},"outputs":[],"source":["# Create the criterion function\n\ncriterion = nn.CrossEntropyLoss()"]},{"cell_type":"markdown","id":"65e64cc0-f7fc-411a-a329-bf60725b17c8","metadata":{},"outputs":[],"source":["Create the training-data loader and the validation-data loader object \n"]},{"cell_type":"code","id":"49d60aa0-56fe-4bd6-b7bd-65019ace462c","metadata":{},"outputs":[],"source":["# Create the training data loader and validation data loader object\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\nvalidation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False)"]},{"cell_type":"markdown","id":"50c8c852-3141-4855-9c66-9b15efd094c3","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"58fc5b7b-e4e8-400c-a30d-13a30ffb0152","metadata":{},"outputs":[],"source":["<a name=\"Train\"><h2 id=\"Train\">Define Neural Network, Criterion function, Optimizer and Train the Model</h2></a> \n"]},{"cell_type":"markdown","id":"2e81b160-9c3d-4e65-9308-a582f5ae2449","metadata":{},"outputs":[],"source":["Create  the model with 100 hidden layers  \n"]},{"cell_type":"code","id":"f33247a8-f6a8-43b8-9e07-e19756d5c8de","metadata":{},"outputs":[],"source":["# Set the parameters for create the model\n\ninput_dim = 28 * 28\nhidden_dim1 = 50\nhidden_dim2 = 50\noutput_dim = 10"]},{"cell_type":"markdown","id":"509bc6c6-ca35-4e1a-bbba-d5a4f1264f74","metadata":{},"outputs":[],"source":["The epoch number in the video is 35. You can try 10 for now. If you try 35, it may take a long time.\n"]},{"cell_type":"code","id":"50aa1d29-41c4-4bd8-8695-bef4f08f1289","metadata":{},"outputs":[],"source":["# Set the number of iterations\n\ncust_epochs = 10"]},{"cell_type":"markdown","id":"996ff3a9-6211-4aec-ad0a-51c4441d6459","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"09abaeaa-df97-4846-af72-c32316bfb89c","metadata":{},"outputs":[],"source":["<a name=\"Test\"><h2 id=\"Test\">Test Sigmoid ,Tanh and Relu</h2></a>\n"]},{"cell_type":"markdown","id":"e3750c1c-f64b-4883-8fd6-73d0eac5eb66","metadata":{},"outputs":[],"source":["Train the network using the Sigmoid activation function\n"]},{"cell_type":"code","id":"2a23a173-0cc6-4080-8b63-4c2a473bcc1e","metadata":{},"outputs":[],"source":["# Train the model with sigmoid function\n\nlearning_rate = 0.01\nmodel = Net(input_dim, hidden_dim1, hidden_dim2, output_dim)\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\ntraining_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs=cust_epochs)"]},{"cell_type":"markdown","id":"21e7f9fe-835c-4389-95c2-f1691afa1f4b","metadata":{},"outputs":[],"source":["Train the network using the Tanh activation function\n"]},{"cell_type":"code","id":"3a2fc961-cc27-4ee5-b4ae-bf0c8a8b983e","metadata":{},"outputs":[],"source":["# Train the model with tanh function\n\nlearning_rate = 0.01\nmodel_Tanh = NetTanh(input_dim, hidden_dim1, hidden_dim2, output_dim)\noptimizer = torch.optim.SGD(model_Tanh.parameters(), lr=learning_rate)\ntraining_results_tanch = train(model_Tanh, criterion, train_loader, validation_loader, optimizer, epochs=cust_epochs)"]},{"cell_type":"markdown","id":"fb640946-f9c3-4c87-a8fb-76c566c9e1e8","metadata":{},"outputs":[],"source":["Train the network using the Relu activation function\n"]},{"cell_type":"code","id":"5f17a9a5-98d1-410c-961f-e1b37e650fb4","metadata":{},"outputs":[],"source":["# Train the model with relu function\n\nlearning_rate = 0.01\nmodelRelu = NetRelu(input_dim, hidden_dim1, hidden_dim2, output_dim)\noptimizer = torch.optim.SGD(modelRelu.parameters(), lr=learning_rate)\ntraining_results_relu = train(modelRelu, criterion, train_loader, validation_loader, optimizer, epochs=cust_epochs)"]},{"cell_type":"markdown","id":"52f1d56e-cd6d-429f-b378-452ac0a1be66","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"b396c071-68a7-40fb-b348-5a4f5b7148d4","metadata":{},"outputs":[],"source":["<a name=\"Result\"><h2 id=\"Result\">Analyze Results</h2></a>\n"]},{"cell_type":"markdown","id":"14b419d9-039e-4b06-a0b8-e602382e6901","metadata":{},"outputs":[],"source":["Compare the training loss for each activation \n"]},{"cell_type":"code","id":"1689a282-7a44-40aa-9f9b-020c20efa047","metadata":{},"outputs":[],"source":["# Compare the training loss\n\nplt.plot(training_results_tanch['training_loss'], label='tanh')\nplt.plot(training_results['training_loss'], label='sigmoid')\nplt.plot(training_results_relu['training_loss'], label='relu')\nplt.ylabel('loss')\nplt.title('training loss iterations')\nplt.legend()"]},{"cell_type":"markdown","id":"cde5492d-efe2-4876-a740-a0498e448bfd","metadata":{},"outputs":[],"source":["Compare the validation loss for each model  \n"]},{"cell_type":"code","id":"6711be5f-c6d3-4c3b-ae8e-9c6c8c6c4c2a","metadata":{},"outputs":[],"source":["# Compare the validation loss\n\nplt.plot(training_results_tanch['validation_accuracy'], label = 'tanh')\nplt.plot(training_results['validation_accuracy'], label = 'sigmoid')\nplt.plot(training_results_relu['validation_accuracy'], label = 'relu') \nplt.ylabel('validation accuracy')\nplt.xlabel('Iteration')   \nplt.legend()"]},{"cell_type":"markdown","id":"1a7fdc82-5b28-468e-a793-b0d6b413bb3c","metadata":{},"outputs":[],"source":["\n","\n","<a href=\"https://dataplatform.cloud.ibm.com/registration/stepone?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork&context=cpdaas&apps=data_science_experience%2Cwatson_machine_learning\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork/Template/module%201/images/Watson_Studio.png\"></a>\n"]},{"cell_type":"markdown","id":"57cf20a4-69f7-4701-9d48-b5de74706ae1","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"f4a79117-3f12-44be-a323-a80c16efe24f","metadata":{},"outputs":[],"source":["<h2>About the Authors:</h2> \n","\n","<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. \n"]},{"cell_type":"markdown","id":"37b9c41b-176f-4bd5-a94b-82fb5864a41a","metadata":{},"outputs":[],"source":["Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/\">Michelle Carey</a>, <a href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a>\n"]},{"cell_type":"markdown","id":"cce0f971-ce45-42a6-8ba3-866d624b456b","metadata":{},"outputs":[],"source":["<!--\n","## Change Log\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2020-09-23  | 2.0  | Srishti  |  Migrated Lab to Markdown and added to course repo in GitLab |\n","\n","\n","-->\n","<hr>\n","\n","## <h3 align=\"center\"> &#169; IBM Corporation. All rights reserved. <h3/>\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"7b6e4006b059bfc484830cf903dd4097cce1c571a4c3dfde6672cfc46c4c8068"},"nbformat":4,"nbformat_minor":4}